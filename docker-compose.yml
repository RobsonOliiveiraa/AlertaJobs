# AlertaJobs - Compose auto-contido (sem variáveis externas)

services:
  # Serviço do seu site HTML
  alerta-jobs-web:
    image: nginx:alpine
    container_name: alerta-jobs-web
    volumes:
      - ./html:/usr/share/nginx/html/
    ports:
      - "80:80"
    networks: [app_net]
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: ["redis-server","--save","60","1000","--loglevel","warning"]
    volumes:
      - redis_data:/data
    networks: [app_net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD","redis-cli","ping"]
      interval: 10s
      timeout: 3s
      retries: 10
    mem_limit: 256m
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: n8n
      POSTGRES_PASSWORD: ChangeThis!123       # <<< TROQUE DEPOIS
      POSTGRES_DB: n8n
      TZ: America/Sao_Paulo
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks: [app_net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL","pg_isready -U n8n -d n8n"]
      interval: 10s
      timeout: 5s
      retries: 10
    mem_limit: 512m
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  n8n:
    image: n8nio/n8n:latest
    ports:
      - "5678:5678"    # depois coloque proxy + HTTPS e feche esta porta
    environment:
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: n8n
      DB_POSTGRESDB_PASSWORD: ChangeThis!123  # <<< igual ao postgres

      QUEUE_BULL_REDIS_HOST: redis
      QUEUE_BULL_REDIS_PORT: 6379

      N8N_ENCRYPTION_KEY: please-change-this-key  # <<< TROQUE DEPOIS
      N8N_HOST: localhost
      N8N_PORT: 5678
      N8N_PROTOCOL: http
      WEBHOOK_URL: http://localhost/

      GENERIC_TIMEZONE: America/Sao_Paulo
      TZ: America/Sao_Paulo
      NODE_ENV: production
    volumes:
      - n8n_data:/home/node/.n8n
      - n8n_files:/files
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks: [app_net]
    restart: unless-stopped
    mem_limit: 1536m
    healthcheck:
      test: ["CMD-SHELL","wget -qO- http://localhost:5678/ | head -n1 >/dev/null 2>&1 || exit 1"]
      interval: 20s
      timeout: 5s
      retries: 15
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

  scraper:
    build:
      context:         # <- se o Dockerfile/app.py estiverem NA RAIZ, troque para: context: .
      dockerfile: scraper/Dockerfile
    container_name: alerta-jobs-scraper
    command: ["python", "/app/app.py"]   # ajuste se seu script tiver outro nome/caminho
    environment:
      TZ: America/Sao_Paulo
      DB_HOST: postgres
      DB_PORT: "5432"
      DB_NAME: n8n
      DB_USER: n8n
      DB_PASSWORD: ChangeThis!123      # o mesmo do serviço postgres
      SCRAPE_SOURCES: "linkedin,infojobs"
      SCRAPE_INTERVAL_MIN: "60"        # se seu app.py usar isso
    depends_on:
      postgres:
        condition: service_healthy
    networks: [app_net]
    restart: unless-stopped
    shm_size: "1gb"                    # ajuda o Selenium/Chrome headless
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  waha:
    image: devlikeapro/whatsapp-http-api:latest
    ports:
      - "3000:3000"
    environment:
      TZ: America/Sao_Paulo
      # API_KEY: changeThisApiKey
    volumes:
      - waha_sessions:/sessions
    networks: [app_net]
    restart: unless-stopped
    mem_limit: 2048m
    healthcheck:
      # usar raiz (200 OK); /health é Plus e retorna 422
      test: ["CMD-SHELL","wget -qO- http://localhost:3000/ >/dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 20
    logging:
      driver: json-file
      options: { max-size: "10m", max-file: "3" }

networks:
  app_net: {}

volumes:
  postgres_data:
  redis_data:
  n8n_data:
  n8n_files:
  waha_sessions:
